"""
Hospital FAQ Chatbot with Rasa + FAISS + llama.cpp

A Python-based chatbot that combines:
- FastAPI for web framework
- Custom intent classification
- FAISS for vector search
- llama.cpp for local LLM inference
- WhatsApp integration via 360dialog
"""

import os
import logging
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Create FastAPI app
app = FastAPI(
    title="Hospital FAQ Chatbot",
    description="A hybrid chatbot using FAISS + llama.cpp for hospital FAQs",
    version="1.0.0"
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "message": "Hospital FAQ Chatbot API",
        "status": "running",
        "version": "1.0.0"
    }

@app.get("/health")
async def health_check():
    """Detailed health check"""
    return {
        "status": "healthy",
        "components": {
            "fastapi": "running",
            "vector_search": "not_initialized",
            "llm": "not_initialized",
            "whatsapp": "not_initialized"
        }
    }

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port) 